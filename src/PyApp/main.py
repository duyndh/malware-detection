import glob
import os

from dataset_loader import *
from feature_extractor import *
from trainer import *
from validator import *

import json


def load_args():

    if not os.environ.get("EDITH_output_dir") is None:
        GlobalVars.output_dir = os.environ.get("EDITH_output_dir")
    prefix_file_name = datetime.now().strftime("%d%m%Y_%H%M%S")
    GlobalVars.output_dir = os.path.join(GlobalVars.output_dir, prefix_file_name)
    os.mkdir(GlobalVars.output_dir)
    log("output_dir: " + GlobalVars.output_dir)

    if not os.environ.get("EDITH_mode_id") is None:
        GlobalVars.mode_id = int(os.environ.get("EDITH_mode_id"))
    log("mode_id: " + ModeEnum.get_name(GlobalVars.mode_id))

    if not os.environ.get("EDITH_feature_id") is None:
        GlobalVars.feature_id = int(os.environ.get("EDITH_feature_id"))
    log("feature_id: " + FeatureEnum.get_name(GlobalVars.feature_id))

    if not os.environ.get("EDITH_sequence_len") is None:
        GlobalVars.sequence_len = int(os.environ.get("EDITH_sequence_len"))
    log("sequence_len: " + str(GlobalVars.sequence_len))

    if not os.environ.get("EDITH_test_ratio") is None:
        GlobalVars.test_ratio = float(os.environ.get("EDITH_test_ratio"))
    log("test_ratio: " + str(GlobalVars.test_ratio))

    if not os.environ.get("EDITH_reduced_size") is None:
        GlobalVars.reduced_size = int(os.environ.get("EDITH_reduced_size"))
    log("reduced_size: " + str(GlobalVars.reduced_size))

    if not os.environ.get("EDITH_benign_dirs") is None:
        GlobalVars.benign_dirs = os.environ.get("EDITH_benign_dirs").split(";")
    log("benign_dirs: " + str(GlobalVars.benign_dirs))

    if not os.environ.get("EDITH_benign_limit") is None:
        GlobalVars.benign_limit = int(os.environ.get("EDITH_benign_limit"))
    log("benign_limit: " + str(GlobalVars.benign_limit))

    if not os.environ.get("EDITH_malware_dirs") is None:
        GlobalVars.malware_dirs = os.environ.get("EDITH_malware_dirs").split(";")
    log("malware_dirs: " + str(GlobalVars.malware_dirs))

    if not os.environ.get("EDITH_malware_limit") is None:
        GlobalVars.malware_limit = int(os.environ.get("EDITH_malware_limit"))
    log("malware_limit: " + str(GlobalVars.malware_limit))

    if not os.environ.get("EDITH_classifier_ids") is None:
        GlobalVars.classifier_ids = [int(x) for x in os.environ.get("EDITH_classifier_ids").split(" ")]
    log("classifier_ids: " + str([ClassifierEnum.get_name(id) for id in GlobalVars.classifier_ids]))

    if not os.environ.get("EDITH_target_type_id") is None:
        GlobalVars.target_type_id = int(os.environ.get("EDITH_target_type_id"))
    log("target_type_id: " + TargetType.get_name(GlobalVars.target_type_id))

    if not os.environ.get("EDITH_target_paths") is None:
        GlobalVars.target_paths = os.environ.get("EDITH_target_paths").split(";")
    log("target_paths: " + str(GlobalVars.target_paths))

    if not os.environ.get("EDITH_clf_path") is None:
        GlobalVars.clf_path = os.environ.get("EDITH_clf_path")
    log("clf_path: " + str(GlobalVars.clf_path))

    if not os.environ.get("EDITH_scl_path") is None:
        GlobalVars.scl_path = os.environ.get("EDITH_scl_path")
    log("scl_path: " + str(GlobalVars.scl_path))

    if not os.environ.get("EDITH_dcp_path") is None:
        GlobalVars.dcp_path = os.environ.get("EDITH_dcp_path")
    log("dcp_path: " + str(GlobalVars.dcp_path))

    if not os.environ.get("EDITH_ext_path") is None:
        GlobalVars.ext_path = os.environ.get("EDITH_ext_path")
    log("ext_path: " + str(GlobalVars.ext_path))

    config_file = open(os.path.join(GlobalVars.output_dir, "config.cfg"), "w")
    config_file.write(
        json.dumps(
            {
                "feature_id": GlobalVars.feature_id,
                "sequence_len": GlobalVars.sequence_len
            }
        )
    )
    config_file.close()

    return


def load_graphs_from_directories(directories, limit_count, limit_size):
    graphs = []
    for directory in directories:
        log("directory: " + directory)

        find_pattern = os.path.join(directory, "**", "*.gcsv")
        file_paths = glob.glob(find_pattern, recursive=True)
        file_count = min(len(file_paths), limit_count - len(graphs))

        file_index = 1
        new_graphs = []

        for file_path in file_paths:

            if len(new_graphs) >= file_count:
                break

            log("{0}/{1} {2}".format(file_index, file_count, file_path))

            if os.path.getsize(file_path) < limit_size:
                new_graph = DatasetLoader.load_graph_file(file_path)
                if len(new_graph) < GlobalVars.limit_len:
                    new_graphs.append(new_graph)

            file_index += 1

        log("found: " + str(len(new_graphs)))
        graphs += new_graphs

    return graphs


def prepare_train_test_dataset(train_dirs, train_limit, test_dirs, test_limit, limit_size):

    train_samples = load_graphs_from_directories(train_dirs, train_limit, limit_size)

    # split single dataset
    if test_dirs is None:
        train_samples, test_samples, _, _ = train_test_split(
            train_samples, [0 for i in range(len(train_samples))], test_size=GlobalVars.test_ratio)
    # 2 separate datasets
    else:
        train_samples = train_samples
        test_samples = load_graphs_from_directories(test_dirs, test_limit, limit_size)

    return train_samples, test_samples


def train_dataset(benign_samples, malware_samples):

    log("benign count: " + str(len(benign_samples)))
    log("malware count: " + str(len(malware_samples)))

    X = benign_samples + malware_samples
    y = [0 for x in range(len(benign_samples))] + [1 for x in range(len(malware_samples))]

    classifier_cvs = Trainer.train_full(GlobalVars.classifier_ids, X, y)
    Trainer.train_k_fold(GlobalVars.classifier_ids, classifier_cvs, X, y)

    return


def test_dataset(benign_samples, malware_samples):

    log("benign count: " + str(len(benign_samples)))
    log("malware count: " + str(len(malware_samples)))

    X = benign_samples + malware_samples
    y = [0 for x in range(len(benign_samples))] + [1 for x in range(len(malware_samples))]

    Validator.test_model(GlobalVars.classifier_ids, X, y)

    return


def predict_multiple_samples():

    classifier = joblib.load(open(GlobalVars.clf_path, "rb"))
    scaler = joblib.load(open(GlobalVars.scl_path, "rb"))
    decomp = joblib.load(open(GlobalVars.dcp_path, "rb"))
    ext_data = joblib.load(open(GlobalVars.ext_path, "rb"))

    if GlobalVars.target_type_id == TargetType.get_index(TargetType.FILES):

        predicts = []
        for target_path in GlobalVars.target_paths:
            sample = DatasetLoader.load_graph_file(target_path)
            predicts.append(Validator.predict_sample(classifier, scaler, decomp, ext_data, sample))

        log("predicts: " + " ".join([str(pred) for pred in predicts]))

    else:
        pass

    return


if __name__ == '__main__':


    # dir = "C:\\Temp\\Output\\18022021_152746"
    # sample = DatasetLoader.load_graph_file("C:\\x\\f\\C_WINDOWS_BT_Sources_Boot_PCAT_bootvhd_dll.gcsv")
    # class_pred = Validator.predict_sample(dir + "\\1_SVM.mdl", dir + "\\data.scl", dir + "\\data.dcp", dir + "\\data.ext", sample)
    #
    # print(class_pred)

    # args
    load_args()

    if GlobalVars.mode_id == ModeEnum.get_index(ModeEnum.TRAIN):
        try:

            # load benign
            log("loading benign samples...")
            benign_train_samples, benign_test_samples = prepare_train_test_dataset(GlobalVars.benign_dirs,
                                                                                   GlobalVars.benign_limit,
                                                                                   GlobalVars.benign_test_dirs,
                                                                                   GlobalVars.benign_test_limit,
                                                                                   GlobalVars.limit_size)

            # load malware
            log("loading malware samples...")
            malware_train_samples, malware_test_samples = prepare_train_test_dataset(GlobalVars.malware_dirs,
                                                                                     GlobalVars.malware_limit,
                                                                                     GlobalVars.malware_test_dirs,
                                                                                     GlobalVars.malware_test_limit,
                                                                                     GlobalVars.limit_size)

            # train
            log("training...")
            train_dataset(benign_train_samples, malware_train_samples)

            # test
            log("testing...")
            test_dataset(benign_test_samples, malware_test_samples)

            log("DONE")

        except Exception as e:
            log("ERROR: " + str(e))

    elif GlobalVars.mode_id == ModeEnum.get_index(ModeEnum.SCAN):
        predict_multiple_samples()

    exit(0)
