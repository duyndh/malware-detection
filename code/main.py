from opcode_dataset_generator import *
from raw_dataset_generator import *
from feature_extractor import *
from data_trainer import *
from visualizer import *
from const_container import *
from util_wrapper import *

import sys
import platform


def init():
    max_int = sys.maxsize

    while True:
        # decrease the maxInt value by factor 10
        # as long as the OverflowError occurs.

        try:
            csv.field_size_limit(max_int)
            break
        except OverflowError:
            max_int = int(max_int / 10)


def generate_raw_dataset(use_benign_dataset):

    if use_benign_dataset:

        for machine, raw_dataset_dir in zip(
                [X86_MACHINE, X64_MACHINE],
                [RAW_BENIGN_DATASET_DIR_X86, RAW_BENIGN_DATASET_DIR_X64]
                ):
            RawDatasetGenerator.generate(
                BENIGN_SCAN_DIRS,
                BENIGN_SCAN_EXTS,
                raw_dataset_dir,
                RAW_FILE_COUNT_LIMIT,
                FILE_SIZE_LIMIT,
                [machine]
            )

    else:
        for machine, raw_dataset_dir in zip(
                [X86_MACHINE, X64_MACHINE],
                [RAW_MALWARE_DATASET_DIR_X86, RAW_MALWARE_DATASET_DIR_X64]
        ):
            RawDatasetGenerator.generate(
                MALWARE_SCAN_DIRS,
                MALWARE_SCAN_EXTS,
                raw_dataset_dir,
                RAW_FILE_COUNT_LIMIT,
                FILE_SIZE_LIMIT,
                [machine]
            )

    pass


def convert_raw_dataset_to_opcode_dataset(use_benign_dataset):

    if use_benign_dataset:
        for machine, raw_dataset_dir, output_csv_file_path in zip(
                                [X86_MACHINE, X64_MACHINE],
                                [RAW_BENIGN_DATASET_DIR_X86, RAW_BENIGN_DATASET_DIR_X64],
                                [OPCODE_BENIGN_DATASET_CSV_FILE_PATH_X86, OPCODE_BENIGN_DATASET_CSV_FILE_PATH_X64]
                                ):
            loaded_files = RawDatasetGenerator.load(
                raw_dataset_dir,
                OPCODE_FILE_COUNT_LIMIT,
                FILE_SIZE_LIMIT,
                [machine]
            )
            OpcodeDatasetGenerator.generate(loaded_files, output_csv_file_path)

    else:
        for machine, raw_dataset_dir, output_csv_file_path in zip(
                [X86_MACHINE, X64_MACHINE],
                [RAW_MALWARE_DATASET_DIR_X86, RAW_MALWARE_DATASET_DIR_X64],
                [OPCODE_MALWARE_DATASET_CSV_FILE_PATH_X86, OPCODE_MALWARE_DATASET_CSV_FILE_PATH_X64]
        ):
            loaded_files = RawDatasetGenerator.load(
                raw_dataset_dir,
                OPCODE_FILE_COUNT_LIMIT,
                FILE_SIZE_LIMIT,
                [machine]
            )
            OpcodeDatasetGenerator.generate(loaded_files, output_csv_file_path)

    pass


def extract_opcode_feature(opcodes, feature_method, sequence_length):

    if feature_method == FeatureMethod.Raw:
        return FeatureExtractor.extract_raw_frequency(opcodes, sequence_length)
    elif feature_method == FeatureMethod.TF:
        return FeatureExtractor.extract_tf(opcodes, sequence_length)
    elif feature_method == FeatureMethod.TF_IDF:
        return FeatureExtractor.extract_tf_idf(opcodes, sequence_length)
    else:
        return None


def train_dataset(feature_method, sequence_length):

    if True:

        print("Training...")
        print("feature method:", feature_method)
        print("sequence length:", sequence_length)

        print("Load benign dataset:", OPCODE_BENIGN_DATASET_CSV_FILE_PATH_X86)
        benign_opcodes_dataset = OpcodeDatasetGenerator.load(
            OPCODE_BENIGN_DATASET_CSV_FILE_PATH_X86,
            TRY_BENIGN_FILE_COUNT_LIMIT)
        benign_op_data = extract_opcode_feature(benign_opcodes_dataset, feature_method, sequence_length)

        print("Load malware dataset:", OPCODE_MALWARE_DATASET_CSV_FILE_PATH_X86)
        malware_opcodes_dataset = OpcodeDatasetGenerator.load(
            OPCODE_MALWARE_DATASET_CSV_FILE_PATH_X86,
            TRY_MALWARE_FILE_COUNT_LIMIT)
        malware_op_data = extract_opcode_feature(malware_opcodes_dataset, feature_method, sequence_length)

        print("n benign:", len(benign_op_data))
        print("n malware:", len(malware_op_data))

        data = benign_op_data + malware_op_data
        labels = [0 for x in benign_op_data] + [1 for x in malware_op_data]

        # init
        X_train, y_train, X_test, y_test, X_train_pca, X_test_pca = DataTrainer.init_train(data, labels, True)

        # train
        cross_predicts = DataTrainer.cross_train(X_train, y_train, X_test, X_train_pca, X_test_pca)

        # score
        scores = DataTrainer.cross_score(cross_predicts, y_test)

        # output
        classifiers = DataTrainer.get_classifiers()
        for classifier_name, score in zip(classifiers, scores):
            print(classifier_name)
            print(score)

        return

    pass

from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import classification_report
from sklearn.svm import SVC

def test():
    print(__doc__)

    # Loading the Digits dataset
    digits = datasets.load_digits()

    # To apply an classifier on this data, we need to flatten the image, to
    # turn the data in a (samples, feature) matrix:
    n_samples = len(digits.images)
    X = digits.images.reshape((n_samples, -1))
    y = digits.target

    # Split the dataset in two equal parts
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.5, random_state=0)

    # Set the parameters by cross-validation
    tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],
                         'C': [1, 10, 100, 1000]},
                        {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]

    scores = ['precision', 'recall']

    for score in scores:

        clf = GridSearchCV(SVC(), tuned_parameters, scoring='%s_macro' % score)

        clf.fit(X_train, y_train)

        print("# Tuning hyper-parameters for %s" % score)
        print()

        # print("Best parameters set found on development set:")
        # print()
        # print(clf.best_params_)
        # print()
        # print("Grid scores on development set:")
        # print()
        # means = clf.cv_results_['mean_test_score']
        # stds = clf.cv_results_['std_test_score']
        # for mean, std, params in zip(means, stds, clf.cv_results_['params']):
        #     print("%0.3f (+/-%0.03f) for %r"
        #           % (mean, std * 2, params))
        # print()

        print("Detailed classification report:")
        print()
        print("The model is trained on the full development set.")
        print("The scores are computed on the full evaluation set.")
        print()
        y_true, y_pred = y_test, clf.predict(X_test)
        print(classification_report(y_true, y_pred))
        print()

    pass


def visualize():

    Visualizer.visualize([
        [ "Nearest Neighbors", 98.27, 97.62, 99.60, 95.72 ],
        [ "Linear SVM", 97.69, 96.85, 98.01, 95.72 ],
        [ "RBF SVM", 74.46, 47.48, 100.00, 31.13 ],
        [ "Decision Tree", 95.38, 93.73, 94.47, 93.00 ],
        [ "Random Forest", 90.04, 85.29, 94.34, 77.82 ],
        [ "Neural Net", 98.41, 97.84, 98.81, 96.89 ],
        [ "Naive Bayes", 80.52, 67.15, 89.61, 53.70 ],
        [ "QDA", 95.53, 93.71, 97.88, 89.88 ],
        [ "LDA", 95.24, 93.44, 95.53, 91.44 ],
        [ "Linear Regression", 97.11, 96.06, 97.21, 94.94 ],
        [ "Logistic Regression", 97.69, 96.86, 97.63, 96.11 ],
        [ "KMeans", 65.08, 12.32, 89.47, 6.61 ],
        [ "AdaBoost", 97.98, 97.25, 98.02, 96.50 ],
        [ "Gradient Boosting", 98.99, 98.64, 98.83, 98.44 ]
    ])

    pass


if __name__ == '__main__':

    # test()

    init()

    if ACTION == Action.COLLECT:
        generate_raw_dataset(COLLECT_BENIGN)

    elif ACTION == Action.CONVERT:
        convert_raw_dataset_to_opcode_dataset(COLLECT_BENIGN)

    elif ACTION == Action.TRAIN:
        train_dataset(TRAINING_FEATURE_METHOD, TRAINING_SEQUENCE_LENGTH)

    elif ACTION == Action.VISUALIZE:
        visualize()

    pass