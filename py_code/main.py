import sys
import csv
import os
import glob
import base64
# import pandas as pd


from feature_extractor import *
from const_container import *
from trainer import *
from validator import *
from dataset_loader import *

def init():
    max_int = sys.maxsize

    while True:
        # decrease the maxInt value by factor 10
        # as long as the OverflowError occurs.

        try:
            csv.field_size_limit(max_int)
            break
        except OverflowError:
            max_int = int(max_int / 10)


def load_graphs_from_directory(dataset_directory, limit_count):

    find_pattern = os.path.join(dataset_directory, "**", "*.graph.csv")
    file_paths = glob.glob(find_pattern, recursive=True)
    file_count = min(len(file_paths), limit_count)
    print("Total:", file_count)

    file_index = 1
    graphs = []
    for file_path in file_paths:

        if file_index > limit_count:
            break

        print(file_index, "/", file_count, file_path)

        graphs.append(DatasetLoader.load_graph(file_path))
        file_index += 1

    return graphs


def build_dataset_features(dataset_directory):

    print("Dataset directory:", dataset_directory)

    graphs = load_graphs_from_directory(dataset_directory)

    # FeatureExtractor.extract_pagerank(raw_graph, 256)
    # FeatureExtractor.extract_tf(graphs, 256, 1)
    FeatureExtractor.extract_tf_idf(graphs, 256, 1)

    pass


def train_dataset(feature_method, sequence_length):

    print("Training...")
    print("feature method:", feature_method)
    print("sequence length:", sequence_length)

    print("Load benign dataset:", BENIGN_DATASET_DIR)
    benign_graphs = load_graphs_from_directory(BENIGN_DATASET_DIR, TRY_BENIGN_FILE_COUNT_LIMIT)
    benign_features = FeatureExtractor.extract_feature(FeatureMethod.PR, benign_graphs, 256, 1)

    print("Load malware dataset:", MALWARE_DATASET_DIR)
    malware_graphs = load_graphs_from_directory(MALWARE_DATASET_DIR, TRY_MALWARE_FILE_COUNT_LIMIT)
    malware_features = FeatureExtractor.extract_feature(FeatureMethod.PR, malware_graphs, 256, 1)

    print("n benign:", len(benign_features))
    print("n malware:", len(malware_features))

    data = benign_features + malware_features
    labels = [0 for x in range(len(benign_features))] + [1 for x in range(len(malware_features))]

    # init
    X_train, y_train, X_test, y_test, X_train_pca, X_test_pca = Trainer.init_train(data, labels, False)

    # train
    cross_predicts = Trainer.cross_train(X_train, y_train, X_test, X_train_pca, X_test_pca)

    # score
    validations = Validator.cross_validate(cross_predicts, y_test)

    # output
    classifiers = Trainer.get_classifiers()
    for classifier_name, validation in zip(classifiers, validations):
        print(classifier_name)
        print(validation)

    return


def test():




    print(v)

    pass

if __name__ == '__main__':

    init()

    #test()

    #build_dataset_features("C:\\Temp\\AsmOut")
    train_dataset(TRAINING_FEATURE_METHOD.PR, TRAINING_SEQUENCE_LENGTH)

    pass