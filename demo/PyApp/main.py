import glob
import os
from datetime import datetime

from dataset_loader import *
from feature_extractor import *
from trainer import *

feature_id = FeatureEnum.get_index(FeatureEnum.TF_IDF)
sequence_len = 1
test_ratio = 0.2
reduced_size = OPCODE_RANGE
benign_dirs = ["c:\\x\\x"]
benign_limit = 10
malware_dirs = ["c:\\y\\y", "c:\\y\\yx"]
malware_limit = 12
classifier_ids = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
log_file_path = "c:\\temp\\output\\log.txt"
model_file_path = "c:\\temp\\output\\model.mdl"


def load_args():

    if True:
        if not os.environ.get("EDITH_feature_id") is None:
            global feature_id
            feature_id = int(os.environ.get("EDITH_feature_id"))

        if not os.environ.get("EDITH_sequence_len") is None:
            global sequence_len
            sequence_len = int(os.environ.get("EDITH_sequence_len"))

        if not os.environ.get("EDITH_test_ratio") is None:
            global test_ratio
            test_ratio = float(os.environ.get("EDITH_test_ratio"))

        if not os.environ.get("EDITH_reduced_size") is None:
            global reduced_size
            reduced_size = int(os.environ.get("EDITH_reduced_size"))

        if not os.environ.get("EDITH_benign_dirs") is None:
            global benign_dirs
            benign_dirs = os.environ.get("EDITH_benign_dirs").split(";")

        if not os.environ.get("EDITH_benign_limit") is None:
            global benign_limit
            benign_limit = int(os.environ.get("EDITH_benign_limit"))

        if not os.environ.get("EDITH_malware_dirs") is None:
            global malware_dirs
            malware_dirs = os.environ.get("EDITH_malware_dirs").split(";")

        if not os.environ.get("EDITH_malware_limit") is None:
            global malware_limit
            malware_limit = int(os.environ.get("EDITH_malware_limit"))

        if not os.environ.get("EDITH_classifier_ids") is None:
            global classifier_ids
            classifier_ids = [int(x) for x in os.environ.get("EDITH_classifier_ids").split(" ")]

        if not os.environ.get("EDITH_log_file_path") is None:
            global log_file_path
            log_file_path = os.environ.get("EDITH_log_file_path")

        if not os.environ.get("EDITH_model_file_path") is None:
            global model_file_path
            model_file_path = os.environ.get("EDITH_model_file_path")

    log("feature: " + FeatureEnum.get_name(feature_id))
    log("sequence len: " + str(sequence_len))
    log("test ratio: " + str(test_ratio))
    log("reduced size: " + str(reduced_size))
    log("benign dirs: " + str(benign_dirs))
    log("benign limit: " + str(benign_limit))
    log("malware dirs: " + str(malware_dirs))
    log("malware limit: " + str(malware_limit))
    log("classifiers: " + str([ClassifierEnum.get_name(id) for id in classifier_ids]))
    log("log file path: " + log_file_path)
    log("model file path: " + model_file_path)


def load_graphs_from_directories(directories, limit_count):

    graphs = []
    for directory in directories:
        log("directory: " + directory)

        find_pattern = os.path.join(directory, "**", "*.gcsv")
        file_paths = glob.glob(find_pattern, recursive=True)
        file_count = min(len(file_paths), limit_count - len(graphs))

        file_index = 1
        new_graphs = []

        for file_path in file_paths:

            if file_index > file_count:
                break

            log("{0}/{1} {2}".format(file_index, file_count, file_path))

            new_graphs.append(DatasetLoader.load_graph_file(file_path))
            file_index += 1

        log("found: " + str(len(new_graphs)))
        graphs += new_graphs

    return graphs


def train_dataset(benign_features, malware_features):

    log("benign count: " + str(len(benign_features)))
    log("malware count: " + str(len(malware_features)))

    X = np.stack(benign_features + malware_features, axis=0)
    y = np.stack([0 for x in range(len(benign_features))] + [1 for x in range(len(malware_features))], axis=0)

    for classifier_id in classifier_ids:

        try:
            Trainer.train_k_fold(classifier_id, X, y)

        except Exception as e:
            log("ERROR: " + str(e))

        # X_train, y_train, X_test, y_test = Trainer.init_training(X, y)
        #
        # log("train count: " + str(len(X_train)))
        # log("test count: " + str(len(X_train)))
        # append_to_file(output_file_path,
        #     "n train: " +  + "\n" +
        #     "n test: " + str(len(X_test)) + "\n" +
        #     "reduced feature size: " + str(len(X_train[0])) + "\n"
        #     )
            # Trainer.train_report(classifier_id, X_train, y_train, X_test, y_test,
            #                      output_file_path,
            #                      output_file_path + ".model")

    return


def log(msg):
    now_time = datetime.now().strftime("%d/%m/%Y %H:%M:%S")
    append_to_file(log_file_path, now_time + " " + msg + "\n")
    print(msg)


if __name__ == '__main__':

    # args
    load_args()

    try:

        # load benign
        log("loading benign samples...")
        benign_graphs = load_graphs_from_directories(benign_dirs, benign_limit)
        benign_features = FeatureExtractor.extract_feature(feature_id, benign_graphs, OPCODE_RANGE, sequence_len)

        # load malware
        log("loading malware samples...")
        malware_graphs = load_graphs_from_directories(malware_dirs, malware_limit)
        malware_features = FeatureExtractor.extract_feature(feature_id, malware_graphs, OPCODE_RANGE, sequence_len)

        # train
        log("training...")
        train_dataset(benign_features, malware_features)

        log("DONE")

    except Exception as e:
        log("ERROR: " + str(e))

    exit(0)
