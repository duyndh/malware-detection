import glob
import os
from datetime import datetime

from dataset_loader import *
from feature_extractor import *
from trainer import *
from validator import *

import test

def load_args():
    if True:
        if not os.environ.get("EDITH_feature_id") is None:
            GlobalVars.feature_id = int(os.environ.get("EDITH_feature_id"))

        if not os.environ.get("EDITH_sequence_len") is None:
            GlobalVars.sequence_len = int(os.environ.get("EDITH_sequence_len"))

        if not os.environ.get("EDITH_test_ratio") is None:
            GlobalVars.test_ratio = float(os.environ.get("EDITH_test_ratio"))

        if not os.environ.get("EDITH_reduced_size") is None:
            GlobalVars.reduced_size = int(os.environ.get("EDITH_reduced_size"))

        if not os.environ.get("EDITH_benign_dirs") is None:
            GlobalVars.benign_dirs = os.environ.get("EDITH_benign_dirs").split(";")

        if not os.environ.get("EDITH_benign_limit") is None:
            GlobalVars.benign_limit = int(os.environ.get("EDITH_benign_limit"))

        if not os.environ.get("EDITH_malware_dirs") is None:
            GlobalVars.malware_dirs = os.environ.get("EDITH_malware_dirs").split(";")

        if not os.environ.get("EDITH_malware_limit") is None:
            GlobalVars.malware_limit = int(os.environ.get("EDITH_malware_limit"))

        if not os.environ.get("EDITH_classifier_ids") is None:
            GlobalVars.classifier_ids = [int(x) for x in os.environ.get("EDITH_classifier_ids").split(" ")]

        if not os.environ.get("EDITH_output_dir") is None:
            GlobalVars.output_dir = os.environ.get("EDITH_output_dir")

    GlobalVars.prefix_file_name = datetime.now().strftime("%d%m%Y_%H%M%S")
    GlobalVars.output_dir = os.path.join(GlobalVars.output_dir, GlobalVars.prefix_file_name)
    os.mkdir(GlobalVars.output_dir)

    #GlobalVars.log_file_path = os.path.join(GlobalVars.output_dir, GlobalVars.prefix_file_name + ".txt")

    log("feature: " + FeatureEnum.get_name(GlobalVars.feature_id))
    log("sequence len: " + str(GlobalVars.sequence_len))
    log("test ratio: " + str(GlobalVars.test_ratio))
    log("reduced size: " + str(GlobalVars.reduced_size))
    log("benign dirs: " + str(GlobalVars.benign_dirs))
    log("benign limit: " + str(GlobalVars.benign_limit))
    log("malware dirs: " + str(GlobalVars.malware_dirs))
    log("malware limit: " + str(GlobalVars.malware_limit))
    log("classifiers: " + str([ClassifierEnum.get_name(id) for id in GlobalVars.classifier_ids]))
    log("output dir: " + GlobalVars.output_dir)

    log("prefix file name: " + GlobalVars.prefix_file_name)

    return


def load_graphs_from_directories(directories, limit_count, limit_size):
    graphs = []
    for directory in directories:
        log("directory: " + directory)

        find_pattern = os.path.join(directory, "**", "*.gcsv")
        file_paths = glob.glob(find_pattern, recursive=True)
        file_count = min(len(file_paths), limit_count - len(graphs))

        file_index = 1
        new_graphs = []

        for file_path in file_paths:

            if len(new_graphs) > file_count:
                break

            log("{0}/{1} {2}".format(file_index, file_count, file_path))

            if os.path.getsize(file_path) < limit_size:
                new_graphs.append(DatasetLoader.load_graph_file(file_path))

            file_index += 1

        log("found: " + str(len(new_graphs)))
        graphs += new_graphs

    return graphs


def prepare_train_test_dataset(train_dirs, train_limit, val_dirs, val_limit, label, limit_size):

    train_samples = load_graphs_from_directories(train_dirs, train_limit, limit_size)

    # split single dataset
    if val_dirs is None:
        train_samples, test_samples, _, _ = train_test_split(
            train_samples, [0 for i in range(len(train_samples))], test_size=GlobalVars.test_ratio)
    # 2 separate datasets
    else:
        train_samples = train_samples
        test_samples = load_graphs_from_directories(val_dirs, val_limit, limit_size)

    return train_samples, test_samples


def train_dataset(benign_samples, malware_samples):

    log("benign count: " + str(len(benign_samples)))
    log("malware count: " + str(len(malware_samples)))

    X = benign_samples + malware_samples
    y = [0 for x in range(len(benign_samples))] + [1 for x in range(len(malware_samples))]

    classifier_cvs = Trainer.train_full(GlobalVars.classifier_ids, X, y)
    Trainer.train_k_fold(GlobalVars.classifier_ids, classifier_cvs, X, y)

    return


def test_dataset(benign_samples, malware_samples):

    log("benign count: " + str(len(benign_samples)))
    log("malware count: " + str(len(malware_samples)))

    X = benign_samples + malware_samples
    y = [0 for x in range(len(benign_samples))] + [1 for x in range(len(malware_samples))]

    Validator.test_model(GlobalVars.classifier_ids, X, y)

    return


if __name__ == '__main__':

    dir = "C:\\Temp\\Output\\18022021_152746"
    sample = DatasetLoader.load_graph_file("C:\\x\\f\\C_WINDOWS_BT_Sources_Boot_PCAT_bootvhd_dll.gcsv")
    class_pred = Validator.predict_sample(dir + "\\1_SVM.mdl", dir + "\\data.scl", dir + "\\data.dcp", dir + "\\data.ext", sample)

    print(class_pred)

    exit(0)

    # args
    load_args()

    try:

        # load benign
        log("loading benign samples...")
        benign_train_samples, benign_test_samples = prepare_train_test_dataset(GlobalVars.benign_dirs,
                                                                               GlobalVars.benign_limit,
                                                                               GlobalVars.benign_val_dirs,
                                                                               GlobalVars.benign_val_limit,
                                                                               0,
                                                                               GlobalVars.limit_size)
            
        # load malware
        log("loading malware samples...")
        malware_train_samples, malware_test_samples = prepare_train_test_dataset(GlobalVars.malware_dirs,
                                                                               GlobalVars.malware_limit,
                                                                               GlobalVars.malware_val_dirs,
                                                                               GlobalVars.malware_val_limit,
                                                                               1,
                                                                               GlobalVars.limit_size)

        # train
        log("training...")
        train_dataset(benign_train_samples, malware_train_samples)

        # test
        log("testing...")
        test_dataset(benign_test_samples, malware_test_samples)

        log("DONE")

    except Exception as e:
        log("ERROR: " + str(e))

    exit(0)
