import glob
import os
from enum import IntEnum

from dataset_loader import *
from feature_extractor import *
from trainer import *

import win32file

def load_graphs_from_directory(output_file_path, directory, limit_count):

    find_pattern = os.path.join(directory, "**", "*.gcsv")
    file_paths = glob.glob(find_pattern, recursive=True)
    file_count = min(len(file_paths), limit_count)
    print("total:", file_count)
    append_to_file(output_file_path, str(file_count) + "\n")

    file_index = 1
    graphs = []
    for file_path in file_paths:

        if file_index > limit_count:
            break

        print(file_index, "/", file_count, file_path)

        graphs.append(DatasetLoader.load_graph_file(file_path))
        file_index += 1

    return graphs


def train_dataset(classifier_ids, benign_features, malware_features, output_file_path, test_ratio, reduced_size):

    print("n benign:", len(benign_features))
    print("n malware:", len(malware_features))

    X = np.stack(benign_features + malware_features, axis=0)
    y = np.stack([0 for x in range(len(benign_features))] + [1 for x in range(len(malware_features))], axis=0)

    if True:
        X_train, y_train, X_test, y_test = Trainer.init_report_train(X, y, test_ratio, reduced_size)

        append_to_file(output_file_path,
            "n train: " + str(len(X_train)) + "\n" +
            "n test: " + str(len(X_test)) + "\n" +
            "reduced feature size: " + str(len(X_train[0])) + "\n"
            )

        for classifier_id in classifier_ids:
            print(ClassifierEnum.get_name(classifier_id))
            Trainer.train_report(classifier_id, X_train, y_train, X_test, y_test, output_file_path)

            # Trainer.train_k_fold(classifier_name, classifiers[classifier_name], X, y)

    return


class calculator:

    def add(self, x, y):
        return x + y

    def increment(self, x):
        x += 1
        return x


if __name__ == '__main__':

    if False:
        main_path = sys.argv[0]
        sys.argv = [
            main_path,
            # feature
            FeatureEnum.get_index(FeatureEnum.TF_IDF),
            # sequence len
            1,
            # test ratio
            "0.2",
            # reduced size
            1024,

            "C:\\Temp\\Demo\\benign5000",
            1000,
            "C:\\Temp\\Demo\\malware5000",
            2000,
            "c:\\temp\\out.txt",

            # classifier ids
            ClassifierEnum.get_index(ClassifierEnum.KNN),
            ClassifierEnum.get_index(ClassifierEnum.Linear_SVM),
            ClassifierEnum.get_index(ClassifierEnum.RBF_SVM),
            ClassifierEnum.get_index(ClassifierEnum.Linear_Regression),
            ClassifierEnum.get_index(ClassifierEnum.Logistic_Regression),
            ClassifierEnum.get_index(ClassifierEnum.Neuron_Network),
            ClassifierEnum.get_index(ClassifierEnum.Naive_Bayes),
            ClassifierEnum.get_index(ClassifierEnum.QDA),
            ClassifierEnum.get_index(ClassifierEnum.LDA),
            ClassifierEnum.get_index(ClassifierEnum.Decision_Tree),
            ClassifierEnum.get_index(ClassifierEnum.Random_Forest),
            ClassifierEnum.get_index(ClassifierEnum.Extra_Trees),
            ClassifierEnum.get_index(ClassifierEnum.Ada_Boost),
            ClassifierEnum.get_index(ClassifierEnum.Gradient_Boosting)
        ]

    if len(sys.argv) < 11:
        exit(0)

    feature_id = int(sys.argv[1])
    sequence_len = int(sys.argv[2])
    test_ratio = float(sys.argv[3])
    reduced_size = int(sys.argv[4])
    benign_dataset_directory = sys.argv[5]
    benign_limit_count = int(sys.argv[6])
    malware_dataset_directory = sys.argv[7]
    malware_limit_count = int(sys.argv[8])
    output_file_path = sys.argv[9]

    append_to_file(output_file_path, str(sys.argv) + "\n")

    classifier_ids = []
    for argv_index in range(10, len(sys.argv)):
        classifier_ids.append(int(sys.argv[argv_index]))

    try:
        append_to_file(output_file_path,
                       "feature: " + FeatureEnum.get_name(feature_id) + "\n" +
                       "sequence len: " + str(sequence_len) + "\n" +
                       "test ratio: " + str(test_ratio) + "\n"
                       )

        # load benign
        print("[INFO]", "Loading benigns...")
        append_to_file(output_file_path, benign_dataset_directory)
        benign_graphs = load_graphs_from_directory(output_file_path, benign_dataset_directory, benign_limit_count)
        append_to_file(output_file_path, "n benign: " + str(len(benign_graphs)) + "\n")
        benign_features = FeatureExtractor.extract_feature(feature_id, benign_graphs, OPCODE_RANGE, sequence_len)

        # load malware
        print("[INFO]", "Loading malwares...")
        append_to_file(output_file_path, malware_dataset_directory)
        malware_graphs = load_graphs_from_directory(output_file_path, malware_dataset_directory, malware_limit_count)
        append_to_file(output_file_path, "n malware: " + str(len(malware_graphs)) + "\n")
        malware_features = FeatureExtractor.extract_feature(feature_id, malware_graphs, OPCODE_RANGE, sequence_len)

        append_to_file(output_file_path,
            "feature size: " + str(len(benign_features[0])) + "\n"
        )

        # train
        print("[INFO]", "Training...")
        train_dataset(classifier_ids, benign_features, malware_features, output_file_path, test_ratio, reduced_size)

        print("[INFO]", "Done")

    except Exception as e:
        print("[ERROR]", str(e))

    exit(0)
